{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "nlp_scrape_clean",
      "provenance": [],
      "authorship_tag": "ABX9TyPKbYytECqLZGSiknZaFCSq"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "e9n-mR6HWHO3",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from bs4 import BeautifulSoup\n",
        "from urllib.request import urlopen\n"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QFVDltolWSkn",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 523
        },
        "outputId": "9ccf7890-a007-4dc9-b8a2-355a00c9baab"
      },
      "source": [
        "#Data source-  HTML webpage\n",
        "myurl = \"https://www.indeed.com/career-advice/resume-samples/information-technology-resumes/data-scientist\"\n",
        "html = urlopen(myurl).read()\n",
        "soupified = BeautifulSoup(html, \"html.parser\")\n",
        "cv = soupified.find(\"div\", {\"class\": \"styles-module--resumeWrapper--1spDn\"})\n",
        "print(cv.get_text(separator=\"\\n\").strip())\n",
        "\n",
        "\n"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Malik Rabb\n",
            "Seattle, WA\n",
            " â€¢ \n",
            "(123) 456-7891\n",
            "mrabb@email.com\n",
            "SUMMARY\n",
            "Data Scientist with strong math background and 3+ years of experience using predictive modeling, data processing, and data mining algorithms to solve challenging business problems. Involved in Python open source community and passionate about deep reinforcement learning.\n",
            "EDUCATION\n",
            "Coral Springs University\n",
            "Current - Current\n",
            "Bachelor of Science in Mathematics\n",
            "EXPERIENCE\n",
            "River Tech, Data Scientist\n",
            "Current - Current\n",
            "Built fuzzy matching algorithm using k-nearest neighbors to identify non-exact matching duplicates\n",
            "Designed and developed real time recommendation engine to rank sales leads for upsell opportunities\n",
            "Refined personalization algorithms for 1M+ customers on web and mobile\n",
            "Transformed raw data into MySQL with custom-made ETL application to prepare unruly data for machine learning\n",
            "Retail Ocean, Data Scientist\n",
            "Current - Current\n",
            "Leveraged 200M+ tweets to develop sentiment analysis model that helped improve sales and marketing strategies\n",
            "Used Python and Spark to scrape, clean, and analyze large datasets\n",
            "Helped build tools for detecting botnets with machine learning and data mining\n",
            "SKILLS\n",
            "2nd place at Coral Springs Big Data Hackathon (out of 150+ participants)\n",
            "Java, Python, C++, Hadoop ecosystem, and MySQL\n",
            "Data cleansing, modeling, and mining\n",
            "Machine learning\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "J-8pjaIBa6dp",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 159
        },
        "outputId": "88c40671-5d20-46fe-a675-599f7f02c29e"
      },
      "source": [
        "#data source- pdf \n",
        "!pip install tika \n"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: tika in /usr/local/lib/python3.6/dist-packages (1.24)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.6/dist-packages (from tika) (2.23.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.6/dist-packages (from tika) (47.3.1)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests->tika) (3.0.4)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests->tika) (2.9)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests->tika) (2020.6.20)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests->tika) (1.24.3)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XIr2ySt8nJpe",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "bb59cf9b-55d8-4e43-b2e5-ec4efc6769a8"
      },
      "source": [
        "from tika import parser\n",
        "raw = parser.from_file('smith_cv.pdf')\n",
        "print(raw['content'])"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "2020-07-03 16:08:23,547 [MainThread  ] [INFO ]  Retrieving http://search.maven.org/remotecontent?filepath=org/apache/tika/tika-server/1.24/tika-server-1.24.jar to /tmp/tika-server.jar.\n",
            "2020-07-03 16:08:24,201 [MainThread  ] [INFO ]  Retrieving http://search.maven.org/remotecontent?filepath=org/apache/tika/tika-server/1.24/tika-server-1.24.jar.md5 to /tmp/tika-server.jar.md5.\n",
            "2020-07-03 16:08:24,664 [MainThread  ] [WARNI]  Failed to see startup log message; retrying...\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Indeed Resume\n",
            "\n",
            "\n",
            "Michael Smith \n",
            "\n",
            "BI / Big Data/ Azure \n",
            "\n",
            "Manchester, UK- Email me on Indeed: indeed.com/r/falicent/140749dace5dc26f \n",
            "\n",
            " \n",
            "\n",
            "10+ years of Experience in Designing, Development, Administration, Analysis, \n",
            "\n",
            "Management inthe Business Intelligence Data warehousing, Client Server \n",
            "\n",
            "Technologies, Web-based Applications, cloud solutions and Databases. \n",
            "\n",
            "Data warehouse: Data analysis, star/ snow flake schema data modeling and design \n",
            "\n",
            "specific todata warehousing and business intelligence environment. \n",
            "\n",
            "Database: Experience in database designing, scalability, back-up and recovery, \n",
            "\n",
            "writing andoptimizing SQL code and Stored Procedures, creating functions, views, \n",
            "\n",
            "triggers and indexes.  \n",
            "\n",
            "Cloud platform: Worked on Microsoft Azure cloud services like Document DB, SQL \n",
            "\n",
            "Azure, StreamAnalytics, Event hub, Power BI, Web Job, Web App, Power BI, Azure \n",
            "\n",
            "data lake analytics(U-SQL). \n",
            "\n",
            "Big Data: Worked Azure data lake store/analytics for big data processing and Azure \n",
            "\n",
            "data factoryto schedule U-SQL jobs. Designed and developed end to end big data \n",
            "\n",
            "solution for data insights.  \n",
            "\n",
            " \n",
            "\n",
            "Willing to relocate: Anywhere \n",
            "\n",
            "WORK EXPERIENCESoftware Engineer \n",
            "\n",
            "Microsoft - Manchester, UK. \n",
            "\n",
            "December 2015 to Present \n",
            "\n",
            "1. Microsoft Rewards Live dashboards: \n",
            "\n",
            "Description: - Microsoft rewards is loyalty program that rewards Users for \n",
            "\n",
            "browsing and shopping online. Microsoft Rewards members can earn points when \n",
            "\n",
            "searching with Bing, browsing with Microsoft Edge and making purchases at the \n",
            "\n",
            "Xbox Store, the Windows Store and the Microsoft Store. Plus, user can pick up \n",
            "\n",
            "bonus points for taking daily quizzes and tours on the Microsoft rewards website. \n",
            "\n",
            "Rewards live dashboards gives a live picture of usage world-wide and by markets \n",
            "\n",
            "like US, Canada, Australia, new user registration count, top/bottom performing \n",
            "\n",
            "rewards offers, orders stats and weekly trends of user activities, orders and new \n",
            "\n",
            "user registrations. the PBI tiles gets refreshed in different frequencies starting \n",
            "\n",
            "from 5 seconds to 30 minutes. \n",
            "\n",
            "Technology/Tools used \n",
            "\n",
            "Event hub, stream analytics and Power BI. \n",
            "\n",
            "Responsibilities \n",
            "\n",
            "Created stream analytics jobs to process event hub data \n",
            "\n",
            "Created Power BI live dashboard to show live usage traffic, weekly trends, cards, \n",
            "\n",
            "charts to showtop/bottom 10 offers and usage metrics. \n",
            "\n",
            "2. Microsoft Rewards Data Insights: \n",
            "\n",
            "Description: - Microsoft rewards is loyalty program that rewards Users for \n",
            "\n",
            "browsing and shopping online. Microsoft Rewards members can earn points when \n",
            "\n",
            "searching with Bing, browsing with Microsoft Edge and making purchases at the \n",
            "\n",
            "Xbox Store, the Windows Store and the Microsoft Store. Plus, user can pick up \n",
            "\n",
            "bonus points for taking daily quizzes and tours on the Microsoft rewards website. \n",
            "\n",
            "Rewards data insights is data analytics and reporting platform, processes 20 \n",
            "\n",
            "million users daily activities and redemption across different markets like US, \n",
            "\n",
            "Canada, Australia. \n",
            "\n",
            "Technology/Tools used \n",
            "\n",
            "Cosmos (Microsoft big-data platform), c#, X-flow job monitoring, Power BI. \n",
            "\n",
            "Responsibilities \n",
            "\n",
            "https://www.indeed.com/r/Dushyant-Bhatt/140749dace5dc26f?isid=rex-download&ikw=download-top&co=IN\n",
            "https://www.indeed.com/r/Dushyant-Bhatt/140749dace5dc26f?isid=rex-download&ikw=download-top&co=IN\n",
            "\n",
            "\n",
            "Created big data scripts in cosmos \n",
            "\n",
            "C# data extractors, processors and reducers for data transformation \n",
            "\n",
            "Power BI dashboards \n",
            "\n",
            "3. End to end tracking Tool: \n",
            "\n",
            "Description: - This is real-time Tracking tool to track different business \n",
            "\n",
            "transactions like order, order response, functional acknowledgement, invoice \n",
            "\n",
            "flowing inside ICOE. It gives flexibility to customers to track their transactions \n",
            "\n",
            "and appropriate error information in-case of any failure. Based on resource based \n",
            "\n",
            "access control the tool gives flexibility to end user to perform different actions \n",
            "\n",
            "like view transactions, search based on different filter criteria and view and \n",
            "\n",
            "download actual message payload. End to end tracking tool stitches all the \n",
            "\n",
            "business transaction like order to cash flow and connects different hops inside \n",
            "\n",
            "ICOE like gateway, routing server, Processing server. It also connects different \n",
            "\n",
            "systems like ICOE, partner end point and SAP. \n",
            "\n",
            "Technology/Tools used \n",
            "\n",
            "Azure Document db, Azure web job and Web APP, RBAC, Angular JS. \n",
            "\n",
            "Responsibilities \n",
            "\n",
            "Document dB stored procedures. \n",
            "\n",
            "Web job to process event hub data and populate Document dbâ€¢ Web App API. \n",
            "\n",
            "Stream analytics job to transform data \n",
            "\n",
            "Power BI reports \n",
            "\n",
            "4. Biztrack Tracking Tool: \n",
            "\n",
            "Description: - This is real-time Tracking tool to track different business \n",
            "\n",
            "transactions like order, order response, functional acknowledgement, invoice \n",
            "\n",
            "flowing inside ICOE. It gives flexibility to customers to track their transactions \n",
            "\n",
            "and appropriate error information in-case of any failure. Based on resource based \n",
            "\n",
            "access control the tool gives flexibility to end user to perform different actions \n",
            "\n",
            "like view transactions, search based on different filter criteria and view and \n",
            "\n",
            "download actual message payload. \n",
            "\n",
            "Technology/Tools used \n",
            "\n",
            "SQL server 2014, SSIS, .net API, Angular JS. \n",
            "\n",
            "Responsibilities \n",
            "\n",
            "ETL solution to transform business transactions data stored in Biztalk tables. \n",
            "\n",
            "SQL azure tables, stored procedures, User defined functions. \n",
            "\n",
            "Performance tuning. \n",
            "\n",
            "Web API enhancements. \n",
            "\n",
            " \n",
            "\n",
            "EDUCATION \n",
            "\n",
            "The University of Manchester - UK \n",
            "\n",
            "2007 \n",
            "\n",
            " \n",
            "\n",
            "SKILLS \n",
            "\n",
            "problem solving (Less than 1 year), project lifecycle (Less than 1 year), project \n",
            "\n",
            "manager (Less than 1 year), technical assistance. (Less than 1 year) \n",
            "\n",
            "ADDITIONAL INFORMATION \n",
            "\n",
            "Professional Skills \n",
            "\n",
            "Excellent analytical, problem solving, communication, knowledge transfer and \n",
            "\n",
            "interpersonalskills with ability to interact with individuals at all the levels \n",
            "\n",
            "Quick learner and maintains cordial relationship with project manager and team \n",
            "\n",
            "members andgood performer both in team and independent job environments \n",
            "\n",
            "Positive attitude towards superiors &amp; peers \n",
            "\n",
            "\n",
            "\n",
            "Supervised junior developers throughout project lifecycle and provided technical \n",
            "\n",
            "assistance. \n",
            "\n",
            "\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CwE9ZmoBpn1q",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        },
        "outputId": "3a32f78f-1ba2-4ebc-cda9-29b0fe4ab494"
      },
      "source": [
        "!pip install nltk"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: nltk in /usr/local/lib/python3.6/dist-packages (3.2.5)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from nltk) (1.12.0)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Nm0URmi5o7jH",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 87
        },
        "outputId": "457d327a-85cd-4ed2-c539-77831941ab90"
      },
      "source": [
        "#Sentence segmentation\n",
        "import nltk\n",
        "nltk.download('punkt')\n",
        "nltk.download('stopwords')\n",
        "from nltk.tokenize import sent_tokenize, word_tokenize\n",
        "resume = raw['content']\n",
        "resume_sentences = sent_tokenize(resume)"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/stopwords.zip.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "U-EBXaiup_JD",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 748
        },
        "outputId": "4766e831-bfd3-49e3-f9da-9f7a267818ad"
      },
      "source": [
        "resume_sentences"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\nIndeed Resume\\n\\n\\nMichael Smith \\n\\nBI / Big Data/ Azure \\n\\nManchester, UK- Email me on Indeed: indeed.com/r/falicent/140749dace5dc26f \\n\\n \\n\\n10+ years of Experience in Designing, Development, Administration, Analysis, \\n\\nManagement inthe Business Intelligence Data warehousing, Client Server \\n\\nTechnologies, Web-based Applications, cloud solutions and Databases.',\n",
              " 'Data warehouse: Data analysis, star/ snow flake schema data modeling and design \\n\\nspecific todata warehousing and business intelligence environment.',\n",
              " 'Database: Experience in database designing, scalability, back-up and recovery, \\n\\nwriting andoptimizing SQL code and Stored Procedures, creating functions, views, \\n\\ntriggers and indexes.',\n",
              " 'Cloud platform: Worked on Microsoft Azure cloud services like Document DB, SQL \\n\\nAzure, StreamAnalytics, Event hub, Power BI, Web Job, Web App, Power BI, Azure \\n\\ndata lake analytics(U-SQL).',\n",
              " 'Big Data: Worked Azure data lake store/analytics for big data processing and Azure \\n\\ndata factoryto schedule U-SQL jobs.',\n",
              " 'Designed and developed end to end big data \\n\\nsolution for data insights.',\n",
              " 'Willing to relocate: Anywhere \\n\\nWORK EXPERIENCESoftware Engineer \\n\\nMicrosoft - Manchester, UK.',\n",
              " 'December 2015 to Present \\n\\n1.',\n",
              " 'Microsoft Rewards Live dashboards: \\n\\nDescription: - Microsoft rewards is loyalty program that rewards Users for \\n\\nbrowsing and shopping online.',\n",
              " 'Microsoft Rewards members can earn points when \\n\\nsearching with Bing, browsing with Microsoft Edge and making purchases at the \\n\\nXbox Store, the Windows Store and the Microsoft Store.',\n",
              " 'Plus, user can pick up \\n\\nbonus points for taking daily quizzes and tours on the Microsoft rewards website.',\n",
              " 'Rewards live dashboards gives a live picture of usage world-wide and by markets \\n\\nlike US, Canada, Australia, new user registration count, top/bottom performing \\n\\nrewards offers, orders stats and weekly trends of user activities, orders and new \\n\\nuser registrations.',\n",
              " 'the PBI tiles gets refreshed in different frequencies starting \\n\\nfrom 5 seconds to 30 minutes.',\n",
              " 'Technology/Tools used \\n\\nEvent hub, stream analytics and Power BI.',\n",
              " 'Responsibilities \\n\\nCreated stream analytics jobs to process event hub data \\n\\nCreated Power BI live dashboard to show live usage traffic, weekly trends, cards, \\n\\ncharts to showtop/bottom 10 offers and usage metrics.',\n",
              " '2.',\n",
              " 'Microsoft Rewards Data Insights: \\n\\nDescription: - Microsoft rewards is loyalty program that rewards Users for \\n\\nbrowsing and shopping online.',\n",
              " 'Microsoft Rewards members can earn points when \\n\\nsearching with Bing, browsing with Microsoft Edge and making purchases at the \\n\\nXbox Store, the Windows Store and the Microsoft Store.',\n",
              " 'Plus, user can pick up \\n\\nbonus points for taking daily quizzes and tours on the Microsoft rewards website.',\n",
              " 'Rewards data insights is data analytics and reporting platform, processes 20 \\n\\nmillion users daily activities and redemption across different markets like US, \\n\\nCanada, Australia.',\n",
              " 'Technology/Tools used \\n\\nCosmos (Microsoft big-data platform), c#, X-flow job monitoring, Power BI.',\n",
              " 'Responsibilities \\n\\nhttps://www.indeed.com/r/Dushyant-Bhatt/140749dace5dc26f?isid=rex-download&ikw=download-top&co=IN\\nhttps://www.indeed.com/r/Dushyant-Bhatt/140749dace5dc26f?isid=rex-download&ikw=download-top&co=IN\\n\\n\\nCreated big data scripts in cosmos \\n\\nC# data extractors, processors and reducers for data transformation \\n\\nPower BI dashboards \\n\\n3.',\n",
              " 'End to end tracking Tool: \\n\\nDescription: - This is real-time Tracking tool to track different business \\n\\ntransactions like order, order response, functional acknowledgement, invoice \\n\\nflowing inside ICOE.',\n",
              " 'It gives flexibility to customers to track their transactions \\n\\nand appropriate error information in-case of any failure.',\n",
              " 'Based on resource based \\n\\naccess control the tool gives flexibility to end user to perform different actions \\n\\nlike view transactions, search based on different filter criteria and view and \\n\\ndownload actual message payload.',\n",
              " 'End to end tracking tool stitches all the \\n\\nbusiness transaction like order to cash flow and connects different hops inside \\n\\nICOE like gateway, routing server, Processing server.',\n",
              " 'It also connects different \\n\\nsystems like ICOE, partner end point and SAP.',\n",
              " 'Technology/Tools used \\n\\nAzure Document db, Azure web job and Web APP, RBAC, Angular JS.',\n",
              " 'Responsibilities \\n\\nDocument dB stored procedures.',\n",
              " 'Web job to process event hub data and populate Document dbâ€¢ Web App API.',\n",
              " 'Stream analytics job to transform data \\n\\nPower BI reports \\n\\n4.',\n",
              " 'Biztrack Tracking Tool: \\n\\nDescription: - This is real-time Tracking tool to track different business \\n\\ntransactions like order, order response, functional acknowledgement, invoice \\n\\nflowing inside ICOE.',\n",
              " 'It gives flexibility to customers to track their transactions \\n\\nand appropriate error information in-case of any failure.',\n",
              " 'Based on resource based \\n\\naccess control the tool gives flexibility to end user to perform different actions \\n\\nlike view transactions, search based on different filter criteria and view and \\n\\ndownload actual message payload.',\n",
              " 'Technology/Tools used \\n\\nSQL server 2014, SSIS, .net API, Angular JS.',\n",
              " 'Responsibilities \\n\\nETL solution to transform business transactions data stored in Biztalk tables.',\n",
              " 'SQL azure tables, stored procedures, User defined functions.',\n",
              " 'Performance tuning.',\n",
              " 'Web API enhancements.',\n",
              " 'EDUCATION \\n\\nThe University of Manchester - UK \\n\\n2007 \\n\\n \\n\\nSKILLS \\n\\nproblem solving (Less than 1 year), project lifecycle (Less than 1 year), project \\n\\nmanager (Less than 1 year), technical assistance.',\n",
              " '(Less than 1 year) \\n\\nADDITIONAL INFORMATION \\n\\nProfessional Skills \\n\\nExcellent analytical, problem solving, communication, knowledge transfer and \\n\\ninterpersonalskills with ability to interact with individuals at all the levels \\n\\nQuick learner and maintains cordial relationship with project manager and team \\n\\nmembers andgood performer both in team and independent job environments \\n\\nPositive attitude towards superiors &amp; peers \\n\\n\\n\\nSupervised junior developers throughout project lifecycle and provided technical \\n\\nassistance.']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-NWlQBUHpA7a",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Word tokenization\n",
        "import functools\n",
        "import operator\n",
        "tokens = list()\n",
        "for sentence in resume_sentences:\n",
        "  tokens.append(word_tokenize(sentence))\n",
        "\n",
        "final_tokens = functools.reduce(operator.iconcat, tokens, [])\n"
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tR9zgkDsuKlF",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#remove stopwords, punctuation, convert to lowercase\n",
        "from nltk.corpus import stopwords\n",
        "from string import punctuation\n",
        "def preprocess_corpus(texts):\n",
        "    mystopwords = set(stopwords.words(\"english\"))\n",
        "    return [token.lower() for token in texts if token not in mystopwords and\n",
        "               not token.isdigit() and token not in punctuation]\n",
        "    \n",
        "\n",
        "tokens = preprocess_corpus(final_tokens)"
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XIqbuvTMxeu1",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 72
        },
        "outputId": "0755edf7-9add-48e6-cce0-182c1850d5ac"
      },
      "source": [
        "#Bag od Words representation\n",
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "count_vect = CountVectorizer()\n",
        "\n",
        "bow_rep = count_vect.fit_transform(resume_sentences)\n",
        "print(\"vocab: \", count_vect.vocabulary_)\n",
        "print(len(count_vect.vocabulary_))"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "vocab:  {'indeed': 130, 'resume': 228, 'michael': 168, 'smith': 246, 'bi': 40, 'big': 41, 'data': 75, 'azure': 36, 'manchester': 162, 'uk': 297, 'email': 95, 'me': 164, 'on': 178, 'com': 61, 'falicent': 110, '140749dace5dc26f': 1, '10': 0, 'years': 324, 'of': 176, 'experience': 105, 'in': 129, 'designing': 84, 'development': 87, 'administration': 15, 'analysis': 19, 'management': 160, 'inthe': 140, 'business': 49, 'intelligence': 137, 'warehousing': 308, 'client': 57, 'server': 240, 'technologies': 269, 'web': 309, 'based': 38, 'applications': 30, 'cloud': 58, 'solutions': 249, 'and': 22, 'databases': 77, 'warehouse': 307, 'star': 254, 'snow': 247, 'flake': 112, 'schema': 235, 'modeling': 172, 'design': 82, 'specific': 251, 'todata': 280, 'environment': 99, 'database': 76, 'scalability': 233, 'back': 37, 'up': 299, 'recovery': 215, 'writing': 320, 'andoptimizing': 24, 'sql': 252, 'code': 60, 'stored': 259, 'procedures': 201, 'creating': 69, 'functions': 120, 'views': 306, 'triggers': 295, 'indexes': 132, 'platform': 192, 'worked': 318, 'microsoft': 169, 'services': 241, 'like': 155, 'document': 89, 'db': 78, 'streamanalytics': 261, 'event': 103, 'hub': 126, 'power': 198, 'job': 145, 'app': 29, 'lake': 150, 'analytics': 21, 'store': 258, 'for': 116, 'processing': 204, 'factoryto': 108, 'schedule': 234, 'jobs': 146, 'designed': 83, 'developed': 85, 'end': 96, 'to': 279, 'solution': 248, 'insights': 136, 'willing': 314, 'relocate': 222, 'anywhere': 27, 'work': 317, 'experiencesoftware': 106, 'engineer': 97, 'december': 79, '2015': 5, 'present': 199, 'rewards': 229, 'live': 156, 'dashboards': 74, 'description': 81, 'is': 142, 'loyalty': 157, 'program': 207, 'that': 272, 'users': 304, 'browsing': 48, 'shopping': 242, 'online': 179, 'members': 165, 'can': 51, 'earn': 92, 'points': 195, 'when': 312, 'searching': 238, 'with': 316, 'bing': 42, 'edge': 93, 'making': 159, 'purchases': 210, 'at': 33, 'the': 273, 'xbox': 322, 'windows': 315, 'plus': 193, 'user': 303, 'pick': 190, 'bonus': 45, 'taking': 266, 'daily': 72, 'quizzes': 212, 'tours': 284, 'website': 310, 'gives': 123, 'picture': 191, 'usage': 301, 'world': 319, 'wide': 313, 'by': 50, 'markets': 163, 'us': 300, 'canada': 52, 'australia': 35, 'new': 175, 'registration': 219, 'count': 67, 'top': 283, 'bottom': 47, 'performing': 189, 'offers': 177, 'orders': 181, 'stats': 256, 'weekly': 311, 'trends': 294, 'activities': 12, 'registrations': 220, 'pbi': 184, 'tiles': 277, 'gets': 122, 'refreshed': 218, 'different': 88, 'frequencies': 117, 'starting': 255, 'from': 118, 'seconds': 239, '30': 6, 'minutes': 171, 'technology': 270, 'tools': 282, 'used': 302, 'stream': 260, 'responsibilities': 227, 'created': 68, 'process': 202, 'dashboard': 73, 'show': 243, 'traffic': 288, 'cards': 53, 'charts': 56, 'showtop': 244, 'metrics': 167, 'reporting': 223, 'processes': 203, '20': 2, 'million': 170, 'redemption': 216, 'across': 10, 'cosmos': 66, 'flow': 114, 'monitoring': 173, 'https': 125, 'www': 321, 'dushyant': 91, 'bhatt': 39, 'isid': 143, 'rex': 230, 'download': 90, 'ikw': 128, 'co': 59, 'scripts': 236, 'extractors': 107, 'processors': 205, 'reducers': 217, 'transformation': 293, 'tracking': 287, 'tool': 281, 'this': 275, 'real': 214, 'time': 278, 'track': 286, 'transactions': 290, 'order': 180, 'response': 226, 'functional': 119, 'acknowledgement': 9, 'invoice': 141, 'flowing': 115, 'inside': 135, 'icoe': 127, 'it': 144, 'flexibility': 113, 'customers': 71, 'their': 274, 'appropriate': 31, 'error': 101, 'information': 134, 'case': 54, 'any': 26, 'failure': 109, 'resource': 225, 'access': 8, 'control': 64, 'perform': 186, 'actions': 11, 'view': 305, 'search': 237, 'filter': 111, 'criteria': 70, 'actual': 13, 'message': 166, 'payload': 183, 'stitches': 257, 'all': 16, 'transaction': 289, 'cash': 55, 'connects': 63, 'hops': 124, 'gateway': 121, 'routing': 231, 'also': 17, 'systems': 264, 'partner': 182, 'point': 194, 'sap': 232, 'rbac': 213, 'angular': 25, 'js': 147, 'populate': 196, 'api': 28, 'transform': 292, 'reports': 224, 'biztrack': 44, '2014': 4, 'ssis': 253, 'net': 174, 'etl': 102, 'biztalk': 43, 'tables': 265, 'defined': 80, 'performance': 187, 'tuning': 296, 'enhancements': 98, 'education': 94, 'university': 298, '2007': 3, 'skills': 245, 'problem': 200, 'solving': 250, 'less': 152, 'than': 271, 'year': 323, 'project': 208, 'lifecycle': 154, 'manager': 161, 'technical': 268, 'assistance': 32, 'additional': 14, 'professional': 206, 'excellent': 104, 'analytical': 20, 'communication': 62, 'knowledge': 149, 'transfer': 291, 'interpersonalskills': 139, 'ability': 7, 'interact': 138, 'individuals': 133, 'levels': 153, 'quick': 211, 'learner': 151, 'maintains': 158, 'cordial': 65, 'relationship': 221, 'team': 267, 'andgood': 23, 'performer': 188, 'both': 46, 'independent': 131, 'environments': 100, 'positive': 197, 'attitude': 34, 'towards': 285, 'superiors': 262, 'amp': 18, 'peers': 185, 'supervised': 263, 'junior': 148, 'developers': 86, 'throughout': 276, 'provided': 209}\n",
            "325\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "a5MKJZ53fA52",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 139
        },
        "outputId": "71addec6-f5bb-4e03-f2e1-22cecc3e4fed"
      },
      "source": [
        "bow_rep.toarray()"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[1, 1, 0, ..., 0, 0, 1],\n",
              "       [0, 0, 0, ..., 0, 0, 0],\n",
              "       [0, 0, 0, ..., 0, 0, 0],\n",
              "       ...,\n",
              "       [0, 0, 0, ..., 0, 0, 0],\n",
              "       [0, 0, 0, ..., 0, 3, 0],\n",
              "       [0, 0, 0, ..., 0, 1, 0]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5DoBUQ0K1arL",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 228
        },
        "outputId": "6825185a-43c3-4648-ba5b-2465527cfb54"
      },
      "source": [
        "\n",
        "!wget -P /tmp/input/ -c \"https://s3.amazonaws.com/dl4j-distribution/GoogleNews-vectors-negative300.bin.gz\"\n",
        "\n"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2020-07-03 17:59:59--  https://s3.amazonaws.com/dl4j-distribution/GoogleNews-vectors-negative300.bin.gz\n",
            "Resolving s3.amazonaws.com (s3.amazonaws.com)... 52.217.33.70\n",
            "Connecting to s3.amazonaws.com (s3.amazonaws.com)|52.217.33.70|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 1647046227 (1.5G) [application/x-gzip]\n",
            "Saving to: â€˜/tmp/input/GoogleNews-vectors-negative300.bin.gzâ€™\n",
            "\n",
            "GoogleNews-vectors- 100%[===================>]   1.53G  46.9MB/s    in 34s     \n",
            "\n",
            "2020-07-03 18:00:33 (46.0 MB/s) - â€˜/tmp/input/GoogleNews-vectors-negative300.bin.gzâ€™ saved [1647046227/1647046227]\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "v_gRgNNjfCYM",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 72
        },
        "outputId": "16f77c2e-efd5-4d6e-c35e-5c531acc1fbd"
      },
      "source": [
        "#Analysing pre trained word embeddings, gensim used to access pretrained embeddingd\n",
        "from gensim.models import Word2Vec, KeyedVectors\n",
        "pretrainedpath = \"/tmp/input/GoogleNews-vectors-negative300.bin.gz\"\n",
        "w2v_model = KeyedVectors.load_word2vec_format(pretrainedpath, binary=True)\n",
        "print('done loading Word2Vec')\n",
        "print(len(w2v_model.vocab)) #Number of words in the vocabulary.\n",
        "print(w2v_model.most_similar['beautiful'])\n",
        "W2v_model['beautiful']"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/smart_open/smart_open_lib.py:253: UserWarning: This function is deprecated, use smart_open.open instead. See the migration notes for details: https://github.com/RaRe-Technologies/smart_open/blob/master/README.rst#migrating-to-the-new-open-function\n",
            "  'See the migration notes for details: %s' % _MIGRATION_NOTES_URL\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "irdqBru_12sY",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}